{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 讀取與訓練資料\n",
    "dir = './sf-crime/'\n",
    "df_train = pd.read_csv(dir + 'train.csv')\n",
    "df_test = pd.read_csv(dir + 'test.csv')\n",
    "df_train.head(5)\n",
    "\n",
    "# 重組資料\n",
    "features = ['Dates', 'DayOfWeek', 'PdDistrict', 'X', 'Y']\n",
    "train_X = df_train[features]\n",
    "train_Y = df_train['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除空值\n",
    "df_train['Resolution']  = df_train['Resolution'].replace('NONE', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict',\n",
       "       'Resolution', 'Address', 'X', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從 Dates 抓取小時\n",
    "import datetime\n",
    "# 2015-05-13 19:52:00\n",
    "df_train['Dates'] = df_train['Dates'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_train['Dates_Hours'] = df_train['Dates'].apply(lambda x: datetime.datetime.strftime(x, '%H')).astype('int64')\n",
    "df_train.drop(['Dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Dates_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>0</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>0</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                      Descript  DayOfWeek PdDistrict  \\\n",
       "0        WARRANTS                WARRANT ARREST  Wednesday   NORTHERN   \n",
       "1  OTHER OFFENSES      TRAFFIC VIOLATION ARREST  Wednesday   NORTHERN   \n",
       "2  OTHER OFFENSES      TRAFFIC VIOLATION ARREST  Wednesday   NORTHERN   \n",
       "3   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO  Wednesday   NORTHERN   \n",
       "4   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO  Wednesday       PARK   \n",
       "\n",
       "       Resolution                    Address           X          Y  \\\n",
       "0  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "1  ARREST, BOOKED         OAK ST / LAGUNA ST -122.425892  37.774599   \n",
       "2  ARREST, BOOKED  VANNESS AV / GREENWICH ST -122.424363  37.800414   \n",
       "3               0   1500 Block of LOMBARD ST -122.426995  37.800873   \n",
       "4               0  100 Block of BRODERICK ST -122.438738  37.771541   \n",
       "\n",
       "   Dates_Hours  \n",
       "0           23  \n",
       "1           23  \n",
       "2           23  \n",
       "3           23  \n",
       "4           23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "features_dummy = ['DayOfWeek', 'PdDistrict', 'Dates_Hours']\n",
    "df_test = df_train[features_dummy]\n",
    "# df_test['Dates_Hours'] = df_test['Dates_Hours'].astype('str') warnings\n",
    "df_test = df_test.astype({\"Dates_Hours\": str})\n",
    "train_X = pd.get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.25, random_state=4)\n",
    "\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# 訓練模型\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "depth:  6\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  7\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  8\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  9\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  10\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  11\n",
      "Acuuracy:  0.22\n",
      "----------\n",
      "depth:  12\n",
      "Acuuracy:  0.22\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "depth_list = [6,7,8,9,10,11,12]\n",
    "depth_acc = []\n",
    "for depth in depth_list:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, criterion='entropy')\n",
    "    # 訓練模型\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print('depth: ', depth)\n",
    "    print(\"Acuuracy: \", round(acc,2))\n",
    "    print('----------')\n",
    "    depth_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(299.2173913043478, 338.79999999999995, 'X[16] <= 0.5\\nentropy = 0.903\\nsamples = 658536\\nvalue = [1149, 57650, 312, 212, 27545, 3248, 1699, 40438, 3202\\n857, 190, 388, 7981, 12545, 111, 1771, 131367, 1439\\n890, 19479, 69228, 94782, 17, 5595, 2318, 17263, 1460\\n7510, 3296, 115, 3390, 369, 23476, 5, 5440, 33492\\n40290, 31607, 6410]'),\n",
       " Text(169.82608695652175, 277.2, 'X[7] <= 0.5\\nentropy = 0.901\\nsamples = 596967\\nvalue = [1098, 51880, 296, 200, 26439, 2623, 1626, 27125, 2858\\n789, 184, 359, 7570, 11680, 103, 1619, 123907, 1304\\n745, 18844, 63623, 84401, 16, 4922, 2220, 15613, 1455\\n6966, 3048, 111, 3137, 350, 21595, 5, 4571, 32290\\n39514, 26075, 5806]'),\n",
       " Text(86.26086956521739, 215.59999999999997, 'X[9] <= 0.5\\nentropy = 0.897\\nsamples = 529930\\nvalue = [795, 44442, 271, 159, 23500, 2460, 1490, 23807, 2671\\n718, 174, 302, 6980, 11014, 84, 1383, 116342, 1214\\n709, 15068, 59052, 71649, 14, 4868, 1684, 13562, 1259\\n5720, 2759, 90, 2834, 327, 18625, 2, 4104, 28256\\n34115, 22833, 4594]'),\n",
       " Text(43.130434782608695, 154.0, 'X[10] <= 0.5\\nentropy = 0.894\\nsamples = 470834\\nvalue = [658, 38077, 249, 122, 21024, 2330, 1342, 22017, 2537\\n656, 149, 247, 6234, 10125, 71, 1120, 108613, 1139\\n689, 12696, 53941, 61720, 14, 4852, 1180, 11439, 1141\\n4762, 2393, 71, 2573, 275, 16261, 2, 3788, 24235\\n27401, 20935, 3756]'),\n",
       " Text(21.565217391304348, 92.39999999999998, 'X[15] <= 0.5\\nentropy = 0.887\\nsamples = 380978\\nvalue = [562, 29750, 212, 75, 18215, 1489, 1075, 15492, 1942\\n566, 132, 135, 5268, 8658, 56, 876, 94926, 779, 547\\n10237, 44633, 47170, 12, 2127, 954, 8720, 914, 3688\\n1841, 45, 2093, 225, 13430, 1, 3038, 20256, 22057\\n16028, 2754]'),\n",
       " Text(10.782608695652174, 30.80000000000001, 'entropy = 0.883\\nsamples = 331778\\nvalue = [465, 25655, 184, 61, 15644, 1366, 933, 14350, 1750\\n504, 105, 107, 4453, 7475, 50, 736, 86005, 679, 521\\n7749, 39447, 40688, 10, 2066, 753, 7645, 604, 2936\\n1566, 37, 1912, 174, 11173, 1, 2764, 16605, 17452\\n14838, 2315]'),\n",
       " Text(32.34782608695652, 30.80000000000001, 'entropy = 0.907\\nsamples = 49200\\nvalue = [97, 4095, 28, 14, 2571, 123, 142, 1142, 192, 62\\n27, 28, 815, 1183, 6, 140, 8921, 100, 26, 2488\\n5186, 6482, 2, 61, 201, 1075, 310, 752, 275, 8\\n181, 51, 2257, 0, 274, 3651, 4605, 1190, 439]'),\n",
       " Text(64.69565217391305, 92.39999999999998, 'X[29] <= 0.5\\nentropy = 0.912\\nsamples = 89856\\nvalue = [96, 8327, 37, 47, 2809, 841, 267, 6525, 595, 90\\n17, 112, 966, 1467, 15, 244, 13687, 360, 142, 2459\\n9308, 14550, 2, 2725, 226, 2719, 227, 1074, 552, 26\\n480, 50, 2831, 1, 750, 3979, 5344, 4907, 1002]'),\n",
       " Text(53.91304347826087, 30.80000000000001, 'entropy = 0.911\\nsamples = 87148\\nvalue = [88, 7890, 36, 43, 2724, 811, 241, 6413, 563, 89\\n17, 111, 961, 1437, 15, 225, 13411, 359, 140, 2430\\n9078, 14179, 2, 2623, 215, 2450, 223, 1036, 515, 26\\n469, 49, 2749, 1, 729, 3815, 5239, 4783, 963]'),\n",
       " Text(75.47826086956522, 30.80000000000001, 'entropy = 0.914\\nsamples = 2708\\nvalue = [8, 437, 1, 4, 85, 30, 26, 112, 32, 1, 0, 1, 5\\n30, 0, 19, 276, 1, 2, 29, 230, 371, 0, 102, 11\\n269, 4, 38, 37, 0, 11, 1, 82, 0, 21, 164, 105\\n124, 39]'),\n",
       " Text(129.3913043478261, 154.0, 'X[32] <= 0.5\\nentropy = 0.909\\nsamples = 59096\\nvalue = [137, 6365, 22, 37, 2476, 130, 148, 1790, 134, 62\\n25, 55, 746, 889, 13, 263, 7729, 75, 20, 2372\\n5111, 9929, 0, 16, 504, 2123, 118, 958, 366, 19\\n261, 52, 2364, 0, 316, 4021, 6714, 1898, 838]'),\n",
       " Text(107.82608695652173, 92.39999999999998, 'X[31] <= 0.5\\nentropy = 0.909\\nsamples = 55828\\nvalue = [121, 5999, 20, 36, 2406, 125, 123, 1722, 122, 62\\n25, 54, 734, 869, 13, 248, 7248, 71, 20, 2277\\n4897, 9471, 0, 16, 480, 1946, 113, 919, 350, 18\\n245, 52, 2268, 0, 307, 3757, 6093, 1817, 784]'),\n",
       " Text(97.04347826086956, 30.80000000000001, 'entropy = 0.91\\nsamples = 52619\\nvalue = [111, 5654, 20, 35, 2302, 117, 114, 1647, 115, 61\\n25, 51, 725, 850, 13, 236, 6770, 68, 19, 2172\\n4691, 9032, 0, 16, 467, 1796, 107, 876, 340, 17\\n235, 51, 2162, 0, 296, 3462, 5489, 1738, 739]'),\n",
       " Text(118.6086956521739, 30.80000000000001, 'entropy = 0.892\\nsamples = 3209\\nvalue = [10, 345, 0, 1, 104, 8, 9, 75, 7, 1, 0, 3, 9\\n19, 0, 12, 478, 3, 1, 105, 206, 439, 0, 0, 13\\n150, 6, 43, 10, 1, 10, 1, 106, 0, 11, 295, 604\\n79, 45]'),\n",
       " Text(150.95652173913044, 92.39999999999998, 'X[0] <= 0.5\\nentropy = 0.892\\nsamples = 3268\\nvalue = [16, 366, 2, 1, 70, 5, 25, 68, 12, 0, 0, 1, 12\\n20, 0, 15, 481, 4, 0, 95, 214, 458, 0, 0, 24\\n177, 5, 39, 16, 1, 16, 0, 96, 0, 9, 264, 621\\n81, 54]'),\n",
       " Text(140.17391304347825, 30.80000000000001, 'entropy = 0.891\\nsamples = 2763\\nvalue = [14, 320, 1, 1, 59, 2, 21, 54, 9, 0, 0, 1, 12\\n17, 0, 9, 412, 4, 0, 68, 182, 375, 0, 0, 22\\n152, 4, 32, 13, 1, 13, 0, 83, 0, 8, 219, 539\\n70, 46]'),\n",
       " Text(161.7391304347826, 30.80000000000001, 'entropy = 0.899\\nsamples = 505\\nvalue = [2, 46, 1, 0, 11, 3, 4, 14, 3, 0, 0, 0, 0, 3\\n0, 6, 69, 0, 0, 27, 32, 83, 0, 0, 2, 25, 1\\n7, 3, 0, 3, 0, 13, 0, 1, 45, 82, 11, 8]'),\n",
       " Text(253.3913043478261, 215.59999999999997, 'X[38] <= 0.5\\nentropy = 0.91\\nsamples = 67037\\nvalue = [303, 7438, 25, 41, 2939, 163, 136, 3318, 187, 71\\n10, 57, 590, 666, 19, 236, 7565, 90, 36, 3776\\n4571, 12752, 2, 54, 536, 2051, 196, 1246, 289, 21\\n303, 23, 2970, 3, 467, 4034, 5399, 3242, 1212]'),\n",
       " Text(215.65217391304347, 154.0, 'X[31] <= 0.5\\nentropy = 0.91\\nsamples = 65013\\nvalue = [296, 7251, 25, 41, 2806, 158, 135, 3258, 185, 70\\n10, 55, 584, 648, 19, 229, 7363, 89, 34, 3480\\n4429, 12421, 2, 49, 520, 2007, 180, 1206, 282, 21\\n294, 23, 2884, 3, 452, 3919, 5214, 3171, 1200]'),\n",
       " Text(194.08695652173913, 92.39999999999998, 'X[32] <= 0.5\\nentropy = 0.91\\nsamples = 61804\\nvalue = [277, 6848, 24, 41, 2697, 152, 123, 3135, 175, 69\\n10, 54, 577, 639, 18, 219, 6944, 88, 33, 3299\\n4223, 11960, 2, 47, 498, 1868, 174, 1142, 273, 20\\n282, 23, 2746, 3, 442, 3664, 4828, 3059, 1128]'),\n",
       " Text(183.30434782608697, 30.80000000000001, 'entropy = 0.91\\nsamples = 58319\\nvalue = [252, 6496, 24, 40, 2595, 145, 114, 2976, 165, 68\\n8, 50, 570, 623, 18, 209, 6479, 87, 32, 3117, 4050\\n11367, 2, 45, 481, 1721, 161, 1095, 252, 20, 271\\n21, 2616, 2, 436, 3373, 4385, 2894, 1059]'),\n",
       " Text(204.8695652173913, 30.80000000000001, 'entropy = 0.906\\nsamples = 3485\\nvalue = [25, 352, 0, 1, 102, 7, 9, 159, 10, 1, 2, 4, 7\\n16, 0, 10, 465, 1, 1, 182, 173, 593, 0, 2, 17\\n147, 13, 47, 21, 0, 11, 2, 130, 1, 6, 291, 443\\n165, 69]'),\n",
       " Text(237.2173913043478, 92.39999999999998, 'X[5] <= 0.5\\nentropy = 0.91\\nsamples = 3209\\nvalue = [19, 403, 1, 0, 109, 6, 12, 123, 10, 1, 0, 1, 7\\n9, 1, 10, 419, 1, 1, 181, 206, 461, 0, 2, 22\\n139, 6, 64, 9, 1, 12, 0, 138, 0, 10, 255, 386\\n112, 72]'),\n",
       " Text(226.43478260869566, 30.80000000000001, 'entropy = 0.909\\nsamples = 2779\\nvalue = [15, 345, 1, 0, 99, 6, 11, 99, 10, 1, 0, 1, 7\\n9, 1, 9, 378, 1, 0, 155, 175, 406, 0, 2, 20\\n118, 6, 55, 9, 1, 11, 0, 117, 0, 9, 223, 327\\n88, 64]'),\n",
       " Text(248.0, 30.80000000000001, 'entropy = 0.911\\nsamples = 430\\nvalue = [4, 58, 0, 0, 10, 0, 1, 24, 0, 0, 0, 0, 0, 0\\n0, 1, 41, 0, 1, 26, 31, 55, 0, 0, 2, 21, 0\\n9, 0, 0, 1, 0, 21, 0, 1, 32, 59, 24, 8]'),\n",
       " Text(291.1304347826087, 154.0, 'X[3] <= 0.5\\nentropy = 0.907\\nsamples = 2024\\nvalue = [7, 187, 0, 0, 133, 5, 1, 60, 2, 1, 0, 2, 6\\n18, 0, 7, 202, 1, 2, 296, 142, 331, 0, 5, 16\\n44, 16, 40, 7, 0, 9, 0, 86, 0, 15, 115, 185\\n71, 12]'),\n",
       " Text(280.3478260869565, 92.39999999999998, 'X[2] <= 0.5\\nentropy = 0.905\\nsamples = 1853\\nvalue = [3, 154, 0, 0, 123, 5, 1, 56, 1, 1, 0, 2, 6\\n15, 0, 6, 189, 0, 2, 288, 129, 312, 0, 5, 14\\n38, 16, 34, 7, 0, 9, 0, 76, 0, 13, 107, 168\\n62, 11]'),\n",
       " Text(269.5652173913044, 30.80000000000001, 'entropy = 0.901\\nsamples = 1687\\nvalue = [2, 135, 0, 0, 119, 5, 0, 47, 1, 1, 0, 2, 5\\n15, 0, 6, 177, 0, 2, 279, 108, 287, 0, 5, 11\\n30, 15, 32, 7, 0, 9, 0, 62, 0, 11, 93, 158, 55\\n8]'),\n",
       " Text(291.1304347826087, 30.80000000000001, 'entropy = 0.913\\nsamples = 166\\nvalue = [1, 19, 0, 0, 4, 0, 1, 9, 0, 0, 0, 0, 1, 0\\n0, 0, 12, 0, 0, 9, 21, 25, 0, 0, 3, 8, 1, 2\\n0, 0, 0, 0, 14, 0, 2, 14, 10, 7, 3]'),\n",
       " Text(301.9130434782609, 92.39999999999998, 'entropy = 0.911\\nsamples = 171\\nvalue = [4, 33, 0, 0, 10, 0, 0, 4, 1, 0, 0, 0, 0, 3\\n0, 1, 13, 1, 0, 8, 13, 19, 0, 0, 2, 6, 0, 6\\n0, 0, 0, 0, 10, 0, 2, 8, 17, 9, 1]'),\n",
       " Text(428.60869565217394, 277.2, 'X[37] <= 0.5\\nentropy = 0.881\\nsamples = 61569\\nvalue = [51, 5770, 16, 12, 1106, 625, 73, 13313, 344, 68, 6\\n29, 411, 865, 8, 152, 7460, 135, 145, 635, 5605\\n10381, 1, 673, 98, 1650, 5, 544, 248, 4, 253, 19\\n1881, 0, 869, 1202, 776, 5532, 604]'),\n",
       " Text(382.7826086956522, 215.59999999999997, 'X[36] <= 0.5\\nentropy = 0.88\\nsamples = 60124\\nvalue = [50, 5674, 16, 12, 1080, 433, 72, 13180, 339, 68, 6\\n28, 405, 857, 8, 151, 7378, 134, 111, 622, 5488\\n10123, 1, 655, 94, 1610, 5, 531, 244, 4, 251, 18\\n1846, 0, 683, 1171, 758, 5433, 585]'),\n",
       " Text(345.04347826086956, 154.0, 'X[29] <= 0.5\\nentropy = 0.879\\nsamples = 59425\\nvalue = [44, 5593, 16, 12, 1065, 365, 72, 13150, 338, 68, 6\\n28, 402, 851, 8, 149, 7340, 134, 84, 618, 5412\\n10028, 1, 635, 92, 1574, 5, 525, 238, 4, 250, 18\\n1825, 0, 620, 1156, 747, 5373, 579]'),\n",
       " Text(323.4782608695652, 92.39999999999998, 'X[18] <= 0.5\\nentropy = 0.877\\nsamples = 58105\\nvalue = [42, 5344, 16, 10, 1045, 360, 65, 13006, 318, 68, 5\\n28, 398, 838, 8, 140, 7208, 130, 83, 606, 5313\\n9836, 1, 626, 91, 1474, 5, 509, 217, 4, 244, 17\\n1786, 0, 607, 1096, 730, 5272, 559]'),\n",
       " Text(312.69565217391306, 30.80000000000001, 'entropy = 0.876\\nsamples = 56633\\nvalue = [41, 5092, 16, 9, 1021, 355, 56, 12840, 297, 66, 4\\n26, 395, 819, 8, 132, 7060, 126, 82, 589, 5166\\n9605, 1, 609, 89, 1372, 5, 497, 199, 4, 237, 16\\n1746, 0, 599, 1047, 708, 5160, 539]'),\n",
       " Text(334.2608695652174, 30.80000000000001, 'entropy = 0.899\\nsamples = 1472\\nvalue = [1, 252, 0, 1, 24, 5, 9, 166, 21, 2, 1, 2, 3\\n19, 0, 8, 148, 4, 1, 17, 147, 231, 0, 17, 2\\n102, 0, 12, 18, 0, 7, 1, 40, 0, 8, 49, 22, 112\\n20]'),\n",
       " Text(366.60869565217394, 92.39999999999998, 'X[3] <= 0.5\\nentropy = 0.899\\nsamples = 1320\\nvalue = [2, 249, 0, 2, 20, 5, 7, 144, 20, 0, 1, 0, 4\\n13, 0, 9, 132, 4, 1, 12, 99, 192, 0, 9, 1, 100\\n0, 16, 21, 0, 6, 1, 39, 0, 13, 60, 17, 101, 20]'),\n",
       " Text(355.82608695652175, 30.80000000000001, 'entropy = 0.901\\nsamples = 1072\\nvalue = [2, 184, 0, 2, 16, 4, 6, 126, 17, 0, 1, 0, 2\\n11, 0, 6, 106, 3, 1, 10, 83, 159, 0, 9, 1, 84\\n0, 9, 11, 0, 6, 1, 33, 0, 9, 47, 15, 92, 16]'),\n",
       " Text(377.39130434782606, 30.80000000000001, 'entropy = 0.881\\nsamples = 248\\nvalue = [0, 65, 0, 0, 4, 1, 1, 18, 3, 0, 0, 0, 2, 2\\n0, 3, 26, 1, 0, 2, 16, 33, 0, 0, 0, 16, 0, 7\\n10, 0, 0, 0, 6, 0, 4, 13, 2, 9, 4]'),\n",
       " Text(420.52173913043475, 154.0, 'X[0] <= 0.5\\nentropy = 0.919\\nsamples = 699\\nvalue = [6, 81, 0, 0, 15, 68, 0, 30, 1, 0, 0, 0, 3, 6\\n0, 2, 38, 0, 27, 4, 76, 95, 0, 20, 2, 36, 0\\n6, 6, 0, 1, 0, 21, 0, 63, 15, 11, 60, 6]'),\n",
       " Text(409.7391304347826, 92.39999999999998, 'X[3] <= 0.5\\nentropy = 0.917\\nsamples = 618\\nvalue = [5, 72, 0, 0, 10, 66, 0, 22, 1, 0, 0, 0, 3, 4\\n0, 2, 28, 0, 27, 4, 66, 82, 0, 17, 2, 32, 0\\n6, 5, 0, 1, 0, 16, 0, 63, 14, 10, 54, 6]'),\n",
       " Text(398.95652173913044, 30.80000000000001, 'entropy = 0.918\\nsamples = 533\\nvalue = [5, 57, 0, 0, 8, 63, 0, 18, 1, 0, 0, 0, 3, 4\\n0, 2, 22, 0, 27, 4, 50, 68, 0, 15, 2, 26, 0\\n3, 5, 0, 1, 0, 15, 0, 60, 12, 7, 49, 6]'),\n",
       " Text(420.52173913043475, 30.80000000000001, 'entropy = 0.884\\nsamples = 85\\nvalue = [0, 15, 0, 0, 2, 3, 0, 4, 0, 0, 0, 0, 0, 0\\n0, 0, 6, 0, 0, 0, 16, 14, 0, 2, 0, 6, 0, 3\\n0, 0, 0, 0, 1, 0, 3, 2, 3, 5, 0]'),\n",
       " Text(431.30434782608694, 92.39999999999998, 'entropy = 0.903\\nsamples = 81\\nvalue = [1, 9, 0, 0, 5, 2, 0, 8, 0, 0, 0, 0, 0, 2\\n0, 0, 10, 0, 0, 0, 10, 13, 0, 3, 0, 4, 0, 0\\n1, 0, 0, 0, 5, 0, 0, 1, 1, 6, 0]'),\n",
       " Text(474.4347826086956, 215.59999999999997, 'X[6] <= 0.5\\nentropy = 0.903\\nsamples = 1445\\nvalue = [1, 96, 0, 0, 26, 192, 1, 133, 5, 0, 0, 1, 6\\n8, 0, 1, 82, 1, 34, 13, 117, 258, 0, 18, 4, 40\\n0, 13, 4, 0, 2, 1, 35, 0, 186, 31, 18, 99, 19]'),\n",
       " Text(463.6521739130435, 154.0, 'X[5] <= 0.5\\nentropy = 0.907\\nsamples = 1183\\nvalue = [1, 78, 0, 0, 23, 141, 1, 114, 5, 0, 0, 1, 6\\n6, 0, 1, 69, 1, 26, 10, 106, 212, 0, 15, 3, 34\\n0, 13, 4, 0, 2, 0, 33, 0, 136, 27, 15, 84, 16]'),\n",
       " Text(452.8695652173913, 92.39999999999998, 'X[1] <= 0.5\\nentropy = 0.91\\nsamples = 915\\nvalue = [1, 64, 0, 0, 19, 94, 1, 95, 3, 0, 0, 1, 6, 5\\n0, 1, 60, 1, 14, 9, 86, 162, 0, 9, 2, 31, 0\\n12, 3, 0, 1, 0, 24, 0, 87, 24, 15, 72, 13]'),\n",
       " Text(442.0869565217391, 30.80000000000001, 'entropy = 0.912\\nsamples = 648\\nvalue = [1, 51, 0, 0, 13, 57, 1, 71, 2, 0, 0, 1, 5, 4\\n0, 1, 51, 1, 5, 5, 64, 112, 0, 9, 1, 25, 0\\n10, 1, 0, 1, 0, 19, 0, 49, 18, 15, 49, 6]'),\n",
       " Text(463.6521739130435, 30.80000000000001, 'entropy = 0.896\\nsamples = 267\\nvalue = [0, 13, 0, 0, 6, 37, 0, 24, 1, 0, 0, 0, 1, 1\\n0, 0, 9, 0, 9, 4, 22, 50, 0, 0, 1, 6, 0, 2\\n2, 0, 0, 0, 5, 0, 38, 6, 0, 23, 7]'),\n",
       " Text(474.4347826086956, 92.39999999999998, 'entropy = 0.88\\nsamples = 268\\nvalue = [0, 14, 0, 0, 4, 47, 0, 19, 2, 0, 0, 0, 0, 1\\n0, 0, 9, 0, 12, 1, 20, 50, 0, 6, 1, 3, 0, 1\\n1, 0, 1, 0, 9, 0, 49, 3, 0, 12, 3]'),\n",
       " Text(485.2173913043478, 154.0, 'entropy = 0.875\\nsamples = 262\\nvalue = [0, 18, 0, 0, 3, 51, 0, 19, 0, 0, 0, 0, 0, 2\\n0, 0, 13, 0, 8, 3, 11, 46, 0, 3, 1, 6, 0, 0\\n0, 0, 0, 1, 2, 0, 50, 4, 3, 15, 3]')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_tree(clf.fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.22082974584648746\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "\n",
    "#預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00       364\n",
      "     class 1       0.18      0.02      0.03     19226\n",
      "     class 2       0.00      0.00      0.00        94\n",
      "     class 3       0.00      0.00      0.00        77\n",
      "     class 4       0.00      0.00      0.00      9210\n",
      "     class 5       0.14      0.01      0.02      1072\n",
      "     class 6       0.00      0.00      0.00       569\n",
      "     class 7       0.23      0.31      0.26     13533\n",
      "     class 8       0.00      0.00      0.00      1078\n",
      "     class 9       0.00      0.00      0.00       309\n",
      "    class 10       0.00      0.00      0.00        66\n",
      "    class 11       0.00      0.00      0.00       103\n",
      "    class 12       0.00      0.00      0.00      2628\n",
      "    class 13       0.00      0.00      0.00      4134\n",
      "    class 14       0.00      0.00      0.00        35\n",
      "    class 15       0.00      0.00      0.00       570\n",
      "    class 16       0.25      0.72      0.37     43533\n",
      "    class 17       0.00      0.00      0.00       464\n",
      "    class 18       0.00      0.00      0.00       335\n",
      "    class 19       0.00      0.00      0.00      6510\n",
      "    class 20       0.00      0.00      0.00     23076\n",
      "    class 21       0.17      0.38      0.24     31400\n",
      "    class 22       0.00      0.00      0.00         5\n",
      "    class 23       0.00      0.00      0.00      1889\n",
      "    class 24       0.00      0.00      0.00       820\n",
      "    class 25       0.00      0.00      0.00      5737\n",
      "    class 26       0.00      0.00      0.00       486\n",
      "    class 27       0.00      0.00      0.00      2475\n",
      "    class 28       0.00      0.00      0.00      1092\n",
      "    class 29       0.00      0.00      0.00        33\n",
      "    class 30       0.00      0.00      0.00      1150\n",
      "    class 31       0.00      0.00      0.00       139\n",
      "    class 32       0.00      0.00      0.00      7938\n",
      "    class 33       0.00      0.00      0.00         1\n",
      "    class 34       0.00      0.00      0.00      1886\n",
      "    class 35       0.00      0.00      0.00     11233\n",
      "    class 36       0.19      0.03      0.05     13491\n",
      "    class 37       0.00      0.00      0.00     10607\n",
      "    class 38       0.00      0.00      0.00      2145\n",
      "\n",
      "    accuracy                           0.22    219513\n",
      "   macro avg       0.03      0.04      0.02    219513\n",
      "weighted avg       0.12      0.22      0.13    219513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target_names = ['class 0', 'class 1', 'class 2']\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "target_names=[]\n",
    "for i in range(0, 39):\n",
    "    target_names.append('class '+str(i))\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Accuracy Score: 0.2218182977773526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%time\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=500)\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred_rfc = rfc.predict(x_test)\n",
    "print(f'Accuracy Score: {metrics.accuracy_score(y_pred_rfc, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
